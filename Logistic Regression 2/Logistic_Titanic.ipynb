{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preprocessing\n",
    "Data Preprocessing is a crucial step in logistic regression to ensure that the model performs optimally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset\n",
    "Begin by loading the dataset, typically with a library like Pandas. Data could be from CSV, SQL databases, or other formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library, a powerful tool for data manipulation, preparation, and analysis.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset for the logistic regression model.\n",
    "dataset1 = pd.read_excel('train_cleaned.xlsx')\n",
    "# dataset1 contains the cleaned training data loaded from 'train_cleaned.xlsx'\n",
    "\n",
    "# Load the testing dataset for model evaluation and prediction.\n",
    "dataset2 = pd.read_excel('test_cleaned.xlsx')\n",
    "# dataset2 contains the cleaned test data loaded from 'test_cleaned.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Survived    891 non-null    int64  \n",
      " 1   Pclass      891 non-null    int64  \n",
      " 2   Sex         891 non-null    int64  \n",
      " 3   Age         891 non-null    float64\n",
      " 4   SibSp       891 non-null    int64  \n",
      " 5   Parch       891 non-null    int64  \n",
      " 6   Fare        891 non-null    float64\n",
      " 7   Embarked    891 non-null    int64  \n",
      " 8   Age.1       714 non-null    float64\n",
      " 9   Embarked.1  889 non-null    float64\n",
      "dtypes: float64(4), int64(6)\n",
      "memory usage: 69.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Display an overview of dataset1, including column names, data types, non-null value counts, and memory usage.\n",
    "dataset1.info()\n",
    "\n",
    "# Note: Columns 8 and 9 contain null values due to data cleaning processes applied to those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      418 non-null    int64  \n",
      " 1   Sex         418 non-null    int64  \n",
      " 2   Age         418 non-null    float64\n",
      " 3   SibSp       418 non-null    int64  \n",
      " 4   Parch       418 non-null    int64  \n",
      " 5   Fare        418 non-null    float64\n",
      " 6   Embarked    418 non-null    int64  \n",
      " 7   Age.1       332 non-null    float64\n",
      " 8   Embarked.1  418 non-null    int64  \n",
      " 9   Fare.1      417 non-null    float64\n",
      "dtypes: float64(4), int64(6)\n",
      "memory usage: 32.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of dataset2, including data types, non-null counts, and memory usage.\n",
    "dataset2.info()\n",
    "\n",
    "# Note: Columns 8, 9, and 10 contain null values due to data cleaning processes applied to those columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the inputs and output\n",
    "Separate your data into features (inputs) and the target variable (output) that the model will predict. In a dataset, this often means selecting all columns but one for features and the remaining column for the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age.1</th>\n",
       "      <th>Embarked.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Age.1  \\\n",
       "0         0       3    1  22.0      1      0   7.2500         0   22.0   \n",
       "1         1       1    0  38.0      1      0  71.2833         1   38.0   \n",
       "2         1       3    0  26.0      0      0   7.9250         0   26.0   \n",
       "3         1       1    0  35.0      1      0  53.1000         0   35.0   \n",
       "4         0       3    1  35.0      0      0   8.0500         0   35.0   \n",
       "5         0       3    1  28.0      0      0   8.4583         2    NaN   \n",
       "6         0       1    1  54.0      0      0  51.8625         0   54.0   \n",
       "7         0       3    1   2.0      3      1  21.0750         0    2.0   \n",
       "8         1       3    0  27.0      0      2  11.1333         0   27.0   \n",
       "9         1       2    0  14.0      1      0  30.0708         1   14.0   \n",
       "\n",
       "   Embarked.1  \n",
       "0         0.0  \n",
       "1         1.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "5         2.0  \n",
       "6         0.0  \n",
       "7         0.0  \n",
       "8         0.0  \n",
       "9         1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of dataset1 to get a quick overview of the data structure and values.\n",
    "dataset1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age.1</th>\n",
       "      <th>Embarked.1</th>\n",
       "      <th>Fare.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2</td>\n",
       "      <td>7.8292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.6292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Age.1  Embarked.1  \\\n",
       "0       3    1  34.5      0      0   7.8292         2   34.5           2   \n",
       "1       3    0  47.0      1      0   7.0000         0   47.0           0   \n",
       "2       2    1  62.0      0      0   9.6875         2   62.0           2   \n",
       "3       3    1  27.0      0      0   8.6625         0   27.0           0   \n",
       "4       3    0  22.0      1      1  12.2875         0   22.0           0   \n",
       "5       3    1  14.0      0      0   9.2250         0   14.0           0   \n",
       "6       3    0  30.0      0      0   7.6292         2   30.0           2   \n",
       "7       2    1  26.0      1      1  29.0000         0   26.0           0   \n",
       "8       3    0  18.0      0      0   7.2292         1   18.0           1   \n",
       "9       3    1  21.0      2      0  24.1500         0   21.0           0   \n",
       "\n",
       "    Fare.1  \n",
       "0   7.8292  \n",
       "1   7.0000  \n",
       "2   9.6875  \n",
       "3   8.6625  \n",
       "4  12.2875  \n",
       "5   9.2250  \n",
       "6   7.6292  \n",
       "7  29.0000  \n",
       "8   7.2292  \n",
       "9  24.1500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of dataset2 to get a quick overview of the data structure and values.\n",
    "dataset2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature columns (columns 1 to 7) from dataset1 for training input variables and store them in X1.\n",
    "X1 = dataset1.iloc[:, 1:8].values\n",
    "# These columns represent the independent variables used to train the model.\n",
    "\n",
    "# Extract feature columns (columns 1 to 6) from dataset2 for testing input variables and store them in X2.\n",
    "X2 = dataset2.iloc[:, 0:7].values\n",
    "# These columns represent the independent variables used to evaluate the model.\n",
    "\n",
    "# Extract the target variable (column 0) from dataset1 for training and store it in y.\n",
    "y = dataset1.iloc[:, 0].values\n",
    "# This column contains the dependent variable, or labels, that the model will learn to predict.\n",
    "\n",
    "# Note: dataset2 does not contain a target variable column since it is intended for testing only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    ,  1.    , 22.    , ...,  0.    ,  7.25  ,  0.    ],\n",
       "       [ 1.    ,  0.    , 38.    , ...,  0.    , 71.2833,  1.    ],\n",
       "       [ 3.    ,  0.    , 26.    , ...,  0.    ,  7.925 ,  0.    ],\n",
       "       ...,\n",
       "       [ 3.    ,  0.    , 28.    , ...,  2.    , 23.45  ,  0.    ],\n",
       "       [ 1.    ,  1.    , 26.    , ...,  0.    , 30.    ,  1.    ],\n",
       "       [ 3.    ,  1.    , 32.    , ...,  0.    ,  7.75  ,  2.    ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the extracted training feature array (X1) to verify the input variables for the model.\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    ,  1.    , 34.5   , ...,  0.    ,  7.8292,  2.    ],\n",
       "       [ 3.    ,  0.    , 47.    , ...,  0.    ,  7.    ,  0.    ],\n",
       "       [ 2.    ,  1.    , 62.    , ...,  0.    ,  9.6875,  2.    ],\n",
       "       ...,\n",
       "       [ 3.    ,  1.    , 38.5   , ...,  0.    ,  7.25  ,  0.    ],\n",
       "       [ 3.    ,  1.    , 27.    , ...,  0.    ,  8.05  ,  0.    ],\n",
       "       [ 3.    ,  1.    , 27.    , ...,  1.    , 22.3583,  1.    ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the extracted testing feature array (X2) to confirm the input variables for model evaluation.\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the extracted target variable array (y) to review the output labels for the training data.\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Training Set and the Test Set\n",
    "Split the data into training and test sets to evaluate the model's performance. This is often done with an 80-20 or 70-30 split using train_test_split from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from the sklearn.model_selection module to facilitate splitting datasets into training and testing subsets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the feature array (X1) and target variable (y) into training and testing sets.\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=0)\n",
    "# 80% of the data will be used for training, and 20% will be reserved for testing the model.\n",
    "# random_state ensures reproducibility of the results.\n",
    "\n",
    "# Split the feature array (X2) into training and testing sets.\n",
    "X2_train, X2_test = train_test_split(X2, test_size=0.2, random_state=0)\n",
    "# The same test size and random state are applied for consistency.\n",
    "\n",
    "# Note: X2 does not have a target variable since it is for testing purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    ,  0.    , 28.    , ...,  2.    , 15.2458,  1.    ],\n",
       "       [ 2.    ,  1.    , 31.    , ...,  0.    , 10.5   ,  0.    ],\n",
       "       [ 2.    ,  1.    , 31.    , ...,  1.    , 37.0042,  1.    ],\n",
       "       ...,\n",
       "       [ 3.    ,  1.    , 28.    , ...,  0.    ,  7.7333,  2.    ],\n",
       "       [ 3.    ,  0.    , 36.    , ...,  0.    , 17.4   ,  0.    ],\n",
       "       [ 2.    ,  1.    , 60.    , ...,  1.    , 39.    ,  0.    ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the training feature array from the first dataset (X1) used for model training.\n",
    "X1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.    ,   1.    ,  28.    , ...,   0.    ,  14.4583,   1.    ],\n",
       "       [  3.    ,   1.    ,  28.    , ...,   0.    ,   7.55  ,   0.    ],\n",
       "       [  3.    ,   1.    ,   7.    , ...,   1.    ,  29.125 ,   2.    ],\n",
       "       ...,\n",
       "       [  1.    ,   0.    ,  31.    , ...,   0.    , 113.275 ,   1.    ],\n",
       "       [  3.    ,   1.    ,  23.    , ...,   0.    ,   7.8542,   0.    ],\n",
       "       [  3.    ,   1.    ,  19.    , ...,   0.    ,   8.05  ,   0.    ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the testing feature array from the first dataset (X1) used for model evaluation.\n",
    "X1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.   ,   1.   ,  55.   , ...,   0.   ,  59.4  ,   1.   ],\n",
       "       [  1.   ,   1.   ,  30.   , ...,   2.   , 151.55 ,   0.   ],\n",
       "       [  1.   ,   1.   ,  61.   , ...,   3.   , 262.375,   1.   ],\n",
       "       ...,\n",
       "       [  3.   ,   0.   ,   1.   , ...,   1.   ,  16.7  ,   0.   ],\n",
       "       [  3.   ,   1.   ,  27.   , ...,   0.   ,   7.75 ,   2.   ],\n",
       "       [  3.   ,   1.   ,  23.   , ...,   0.   ,  13.9  ,   0.   ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the training feature array from the second dataset (X2) for model testing.\n",
    "X2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.    ,   1.    ,  14.5   ,   8.    ,   2.    ,  69.55  ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.55  ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  53.    ,   0.    ,   0.    ,  27.4458,\n",
       "          1.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.75  ,\n",
       "          2.    ],\n",
       "       [  3.    ,   0.    ,  45.    ,   1.    ,   0.    ,  14.1083,\n",
       "          0.    ],\n",
       "       [  1.    ,   1.    ,  55.    ,   1.    ,   1.    ,  93.5   ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  23.    ,   0.    ,   1.    ,  83.1583,\n",
       "          1.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.8958,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,   9.    ,   0.    ,   1.    ,   3.1708,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  21.    ,   0.    ,   0.    ,   7.8542,\n",
       "          0.    ],\n",
       "       [  2.    ,   0.    ,  31.    ,   0.    ,   0.    ,  21.    ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  36.    ,   0.    ,   0.    , 262.375 ,\n",
       "          1.    ],\n",
       "       [  2.    ,   1.    ,  23.    ,   1.    ,   0.    ,  10.5   ,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  23.    ,   0.    ,   0.    ,  10.5   ,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  18.    ,   0.    ,   0.    ,  73.5   ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   8.05  ,\n",
       "          0.    ],\n",
       "       [  3.    ,   0.    ,  22.    ,   2.    ,   0.    ,   8.6625,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  41.    ,   0.    ,   0.    ,  13.    ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  23.    ,   1.    ,   0.    ,  82.2667,\n",
       "          0.    ],\n",
       "       [  3.    ,   0.    ,  27.    ,   8.    ,   2.    ,  69.55  ,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  26.    ,   0.    ,   0.    ,  13.    ,\n",
       "          0.    ],\n",
       "       [  3.    ,   0.    ,  21.    ,   0.    ,   0.    ,   8.6625,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  27.    ,   0.    ,   0.    ,  12.875 ,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  27.    ,   0.    ,   0.    ,  15.5792,\n",
       "          1.    ],\n",
       "       [  3.    ,   1.    ,  31.    ,   3.    ,   0.    ,  18.    ,\n",
       "          0.    ],\n",
       "       [  1.    ,   1.    ,  24.    ,   1.    ,   0.    ,  82.2667,\n",
       "          0.    ],\n",
       "       [  3.    ,   0.    ,  27.    ,   0.    ,   0.    ,   8.1125,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  32.5   ,   0.    ,   0.    ,   9.5   ,\n",
       "          0.    ],\n",
       "       [  1.    ,   1.    ,  55.    ,   0.    ,   0.    ,  50.    ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  18.    ,   0.    ,   0.    ,   8.6625,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  45.    ,   0.    ,   0.    , 262.375 ,\n",
       "          1.    ],\n",
       "       [  1.    ,   0.    ,  48.    ,   1.    ,   0.    , 106.425 ,\n",
       "          1.    ],\n",
       "       [  3.    ,   0.    ,  22.    ,   1.    ,   0.    ,  13.9   ,\n",
       "          0.    ],\n",
       "       [  2.    ,   0.    ,  24.    ,   1.    ,   0.    ,  27.7208,\n",
       "          1.    ],\n",
       "       [  3.    ,   0.    ,  27.    ,   0.    ,   0.    ,   7.75  ,\n",
       "          2.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.2292,\n",
       "          1.    ],\n",
       "       [  2.    ,   1.    ,  43.    ,   0.    ,   1.    ,  21.    ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  33.    ,   0.    ,   0.    , 151.55  ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  35.    ,   0.    ,   0.    , 211.5   ,\n",
       "          1.    ],\n",
       "       [  3.    ,   0.    ,  27.    ,   1.    ,   0.    ,  14.4542,\n",
       "          1.    ],\n",
       "       [  2.    ,   0.    ,  24.    ,   1.    ,   1.    ,  37.0042,\n",
       "          1.    ],\n",
       "       [  2.    ,   1.    ,  30.    ,   0.    ,   0.    ,  13.    ,\n",
       "          0.    ],\n",
       "       [  3.    ,   0.    ,  27.    ,   0.    ,   0.    ,   7.75  ,\n",
       "          2.    ],\n",
       "       [  3.    ,   0.    ,  22.    ,   0.    ,   0.    ,  39.6875,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  27.    ,   0.    ,   0.    ,  15.0458,\n",
       "          1.    ],\n",
       "       [  3.    ,   0.    ,  36.    ,   0.    ,   2.    ,  12.1833,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   8.05  ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  21.    ,   0.    ,   0.    ,   7.75  ,\n",
       "          2.    ],\n",
       "       [  3.    ,   1.    ,  17.    ,   0.    ,   0.    ,   7.8958,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  21.    ,   0.    ,   0.    ,  13.    ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   1.    ,   1.    ,  22.3583,\n",
       "          1.    ],\n",
       "       [  3.    ,   0.    ,  30.    ,   0.    ,   0.    ,   7.6292,\n",
       "          2.    ],\n",
       "       [  3.    ,   0.    ,  47.    ,   1.    ,   0.    ,   7.    ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.575 ,\n",
       "          0.    ],\n",
       "       [  1.    ,   1.    ,  42.    ,   0.    ,   0.    ,  26.55  ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  26.    ,   1.    ,   0.    , 136.7792,\n",
       "          1.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.75  ,\n",
       "          2.    ],\n",
       "       [  3.    ,   0.    ,  27.    ,   0.    ,   4.    ,  25.4667,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  20.    ,   0.    ,   0.    ,   7.8542,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.25  ,\n",
       "          0.    ],\n",
       "       [  2.    ,   1.    ,  34.    ,   1.    ,   0.    ,  26.    ,\n",
       "          0.    ],\n",
       "       [  2.    ,   0.    ,  27.    ,   0.    ,   0.    ,  21.    ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  64.    ,   0.    ,   2.    ,  83.1583,\n",
       "          1.    ],\n",
       "       [  3.    ,   1.    ,  27.    ,   0.    ,   0.    ,   7.75  ,\n",
       "          2.    ],\n",
       "       [  3.    ,   1.    ,  43.    ,   0.    ,   0.    ,   7.8958,\n",
       "          0.    ],\n",
       "       [  2.    ,   0.    ,  21.    ,   0.    ,   1.    ,  21.    ,\n",
       "          0.    ],\n",
       "       [  3.    ,   0.    ,  36.    ,   0.    ,   2.    ,  15.9   ,\n",
       "          0.    ],\n",
       "       [  2.    ,   0.    ,  20.    ,   2.    ,   1.    ,  23.    ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  22.    ,   0.    ,   1.    ,  61.9792,\n",
       "          1.    ],\n",
       "       [  3.    ,   1.    ,  25.    ,   0.    ,   0.    ,   7.925 ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  24.    ,   0.    ,   0.    ,   7.8542,\n",
       "          0.    ],\n",
       "       [  3.    ,   0.    ,  22.    ,   1.    ,   1.    ,  12.2875,\n",
       "          0.    ],\n",
       "       [  2.    ,   0.    ,  30.    ,   1.    ,   0.    ,  13.8583,\n",
       "          1.    ],\n",
       "       [  1.    ,   0.    ,  31.    ,   0.    ,   0.    , 134.5   ,\n",
       "          1.    ],\n",
       "       [  1.    ,   0.    ,  35.    ,   1.    ,   0.    ,  57.75  ,\n",
       "          1.    ],\n",
       "       [  2.    ,   1.    ,  14.    ,   0.    ,   0.    ,  65.    ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  14.    ,   0.    ,   0.    ,   9.225 ,\n",
       "          0.    ],\n",
       "       [  2.    ,   0.    ,  20.    ,   0.    ,   0.    ,  36.75  ,\n",
       "          0.    ],\n",
       "       [  3.    ,   1.    ,  22.    ,   0.    ,   0.    ,   7.225 ,\n",
       "          1.    ],\n",
       "       [  1.    ,   0.    ,  43.    ,   1.    ,   0.    ,  55.4417,\n",
       "          1.    ],\n",
       "       [  2.    ,   1.    ,  26.    ,   1.    ,   1.    ,  29.    ,\n",
       "          0.    ],\n",
       "       [  1.    ,   0.    ,  27.    ,   0.    ,   0.    ,  31.6833,\n",
       "          0.    ],\n",
       "       [  1.    ,   1.    ,  31.    ,   0.    ,   0.    ,  28.5375,\n",
       "          1.    ],\n",
       "       [  2.    ,   1.    ,  29.    ,   1.    ,   0.    ,  26.    ,\n",
       "          0.    ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the testing feature array from the second dataset (X2).\n",
    "X2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the training target variable (output labels) corresponding to X1.\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the testing target variable (output labels) corresponding to X1.\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "Normalize or standardize the feature values to improve the model's convergence speed and performance. Standardization is common for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.49835483,  0.71506099,  1.89816157, ..., -0.40021756,\n",
       "         0.42751192,  0.75836712],\n",
       "       [-1.49835483,  0.71506099,  0.01767879, ...,  1.52313013,\n",
       "         2.05018239, -0.68080684],\n",
       "       [-1.49835483,  0.71506099,  2.34947744, ...,  2.48480397,\n",
       "         4.00170116,  0.75836712],\n",
       "       ...,\n",
       "       [ 0.8622608 , -1.39848211, -2.16368124, ...,  0.56145629,\n",
       "        -0.32439289, -0.68080684],\n",
       "       [ 0.8622608 ,  0.71506099, -0.20797914, ..., -0.40021756,\n",
       "        -0.48199355,  2.19754108],\n",
       "       [ 0.8622608 ,  0.71506099, -0.50885639, ..., -0.40021756,\n",
       "        -0.37369813, -0.68080684]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the StandardScaler class from the sklearn.preprocessing module.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# StandardScaler is used to standardize features by removing the mean and scaling to unit variance.\n",
    "# This process helps in normalizing the data, which can improve the performance and convergence of machine learning algorithms.\n",
    "\n",
    "# Create an instance of the StandardScaler.\n",
    "sc = StandardScaler()  \n",
    "\n",
    "# Fit the scaler to the training feature array from the first dataset (X1_train) \n",
    "X1_train = sc.fit_transform(X1_train)\n",
    "# and transform it to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "# Fit the scaler to the training feature array from the second dataset (X2_train)\n",
    "X2_train = sc.fit_transform(X2_train)\n",
    "# and transform it in the same way. \n",
    "# Note that this step applies scaling independently to the second dataset, \n",
    "# which may not be ideal in some contexts, such as when the scaler should be fit on the combined data.\n",
    "\n",
    "\n",
    "# Display the standardized training feature arrays for both datasets.\n",
    "X1_train  # Standardized training features from the first dataset\n",
    "X2_train  # Standardized training features from the second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81925059, -1.37207547, -0.10684835, ...,  1.95926403,\n",
       "        -0.33167904,  0.99748327],\n",
       "       [-0.38096838,  0.72882288,  0.12218133, ..., -0.47741019,\n",
       "        -0.42640542, -0.56341363],\n",
       "       [-0.38096838,  0.72882288,  0.12218133, ...,  0.74092692,\n",
       "         0.10261958,  0.99748327],\n",
       "       ...,\n",
       "       [ 0.81925059,  0.72882288, -0.10684835, ..., -0.47741019,\n",
       "        -0.48162887,  2.55838016],\n",
       "       [ 0.81925059, -1.37207547,  0.50389745, ..., -0.47741019,\n",
       "        -0.28868112, -0.56341363],\n",
       "       [-0.38096838,  0.72882288,  2.33613483, ...,  0.74092692,\n",
       "         0.14245584, -0.56341363]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the standardized training feature arrays from the first dataset\n",
    "X1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.49835483,  0.71506099,  1.89816157, ..., -0.40021756,\n",
       "         0.42751192,  0.75836712],\n",
       "       [-1.49835483,  0.71506099,  0.01767879, ...,  1.52313013,\n",
       "         2.05018239, -0.68080684],\n",
       "       [-1.49835483,  0.71506099,  2.34947744, ...,  2.48480397,\n",
       "         4.00170116,  0.75836712],\n",
       "       ...,\n",
       "       [ 0.8622608 , -1.39848211, -2.16368124, ...,  0.56145629,\n",
       "        -0.32439289, -0.68080684],\n",
       "       [ 0.8622608 ,  0.71506099, -0.20797914, ..., -0.40021756,\n",
       "        -0.48199355,  2.19754108],\n",
       "       [ 0.8622608 ,  0.71506099, -0.50885639, ..., -0.40021756,\n",
       "        -0.37369813, -0.68080684]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the standardized training feature arrays from the second dataset\n",
    "X2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Building and training the model\n",
    "Building and training a model is a multi-step process that involves several key components in the machine learning process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "\n",
    "Choose the appropriate algorithm for your problem. In the case of logistic regression, you can use libraries like Scikit-Learn to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LogisticRegression class from sklearn.linear_model module.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# This class is used to create a logistic regression model, \n",
    "# which is a statistical method for predicting binary outcomes (0 or 1) based on one or more predictor variables. \n",
    "\n",
    "# Instantiate the logistic regression model.\n",
    "model = LogisticRegression(random_state=0) \n",
    "# The random_state parameter is set to 0 to ensure reproducibility of results \n",
    "# by controlling the random number generator used during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Train the model using the training dataset. This process involves feeding the input features and corresponding target labels to the model so it can learn the relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the machine learning model using the training feature array (X1_train) and the corresponding target variable (y_train).\n",
    "model.fit(X1_train, y_train)\n",
    "# The fit method adjusts the model parameters based on the training data to learn the underlying patterns for making predictions.\n",
    "\n",
    "# Note: y_train cannot be used as the target variable for X2_train due to \n",
    "# inconsistencies in the number of features and the absence of a target variable in the second dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Once the model is trained, you can use it to make predictions on new or unseen data. This involves applying the model to the test dataset or any other data points to infer the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to make predictions on the standardized testing feature array (X1_test).\n",
    "y_pred1 = model.predict(sc.transform(X1_test))\n",
    "# The sc.transform() method standardizes the test data using the parameters learned from the training data.\n",
    "\n",
    "# Use the trained model to make predictions on the standardized testing feature array (X2_test).\n",
    "y_pred2 = model.predict(sc.transform(X2_test))\n",
    "# Similar to the previous line, sc.transform() standardizes the test data to ensure consistency with the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the predictions made by the model for the first testing dataset (X1_test).\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the actual target values (y_test) to facilitate comparison with the predicted values (y_pred1).\n",
    "y_test\n",
    "# This helps in evaluating the model's accuracy and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the predictions made by the model for the second testing dataset (X2_test).\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the prediction of a single data point with:\n",
    "\n",
    "1. Pclass = 3\n",
    "2. Sex = 1\n",
    "3. Age = 20\n",
    "4. SibSp = 1\n",
    "5. Parch = 1\n",
    "6. Fare = 26\n",
    "7. Embarked = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the trained model to make a prediction for a new sample with specified feature values.\n",
    "model.predict(sc.transform([[3, 1, 20, 1, 1, 26, 2]]))\n",
    "# The transform method is applied to scale the input features using the same parameters as the training data to ensure consistent data preprocessing.\n",
    "# The predicted output will indicate the model's classification for this input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the specified features, the prediction is 0, indicating a classification of 'deceased'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Evaluating the model\n",
    "Evaluating a logistic regression model typically involves several metrics, including the confusion matrix and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "A confusion matrix is used to evaluate the performance of a classification model. It compares the predicted classifications to the actual classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[96, 14],\n",
       "       [20, 49]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix using scikit-learn's confusion_matrix function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# This function compares the true labels (y_test) with the predicted labels (y_pred1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "# y_test: the true labels of the test dataset\n",
    "# y_pred1: the predicted labels produced by the model\n",
    "# The confusion matrix will show the counts of True Positives, True Negatives, False Positives, and False Negatives\n",
    "\n",
    "# Note: Ensure that the predicted labels (y_pred2) have the same number of samples as y_test\n",
    "# We cannot use y_pred2 as it may lead to an error if the lengths do not match.\n",
    "\n",
    "# Output the confusion matrix\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "The following code will visualize the confusion matrix to provide a clear representation of the model's performance. This helps in understanding the distribution of true positives, true negatives, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary libraries for plotting and visualization\n",
    "import matplotlib.pyplot as plt  \n",
    "# Matplotlib for general plotting\n",
    "import seaborn as sns  \n",
    "# Seaborn for enhanced visualization features\n",
    "\n",
    "# Setting up the figure for the heatmap\n",
    "plt.figure(figsize=(8, 6))  \n",
    "# Specify the size of the figure (width, height in inches)\n",
    "\n",
    "# Create a heatmap for the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['No', 'Yes'],  # Labels for the x-axis (predicted labels)\n",
    "            yticklabels=['No', 'Yes'])  # Labels for the y-axis (true labels\n",
    "# The heatmap visually represents the values in the confusion matrix (cm)\n",
    "\n",
    "# Set axes labels and title for the plot\n",
    "plt.ylabel('True label')  # Label for the y-axis\n",
    "plt.xlabel('Predicted label')  # Label for the x-axis\n",
    "plt.title('Confusion Matrix')  # Title for the heatmap\n",
    "\n",
    "# Display the plot\n",
    "plt.show()  \n",
    "# Render the heatmap to the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Accuracy is a simple metric that indicates the proportion of correctly classified instances out of the total instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the counts from the confusion matrix\n",
    "TP = 96  # True Positives: correctly predicted positive cases\n",
    "TN = 49  # True Negatives: correctly predicted negative cases\n",
    "FP = 20  # False Positives: incorrectly predicted positive cases\n",
    "FN = 14  # False Negatives: incorrectly predicted negative cases\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# Accuracy is the ratio of correctly predicted cases (TP + TN) to the total number of cases.\n",
    "\n",
    "# Output the accuracy\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy using scikit-learn's accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# This is another way of finding the accuracy of the model\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "# y_test: the true labels of the test dataset\n",
    "# y_pred1: the predicted labels by the model\n",
    "\n",
    "# Output the accuracy\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
